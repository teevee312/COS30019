**Abstract**

Conflicts fueled by political, economic, and ideological factors have shaped civilisations throughout human history, making war a distinguishing feature. In the past, human strategy and decision-making have been important components of warfare. However, the battlefield is a difficult area for ethical evaluation. The most serious kinds of injury are inflicted, including death, disfigurement, property destruction, and environmental ruin. Additionally, making decisions during a battle is done in a chaotic and urgent environment.

**Introduction**

Through the time, war has changed as a result of technological advancements, embracing automation, cyberwarfare, and artificial intelligence. Artificial Intelligence (AI) is a technological advancement that uses computers or machines to mimic human intelligence[1]. Reducing combatant deaths and increasing military performance are the goals of integrating AI into operations[1]. Drones and robotic systems with AI capabilities are already being utilized for target identification, reconnaissance, and even precision strikes, which lowers the hazards for human soldiers. AI-powered cybersecurity solutions are also essential for protecting against cyberattacks that have the potential to destroy a country's infrastructure.

Allowing AI systems to make decisions that could mean the difference between life and death, however, raises serious questions of responsibility, bias, international law compliance, and the ethical ramifications of giving robots the ability to use lethal force; in this case it is called lethal autonomous weapon systems (LAWS). People are concerned that programmers are unable to predict what an AI-powered weapon system's computer will "learn" given the algorithm they employ. When the system is deployed, they are unable to determine if it will adhere to the human right to life, which is applicable in both times of war and peace, or the ban on the use of force[2].

The aim of this research is to prove that although there are frequent worries about ethics, responsibility, and dangers associated with the use of artificial intelligence (AI) in combat, AI also has a lot to offer, including the potential to improve military operations while reducing human suffering. When we know how to use properly and responsibility, artificial intelligence can increase productivity, accuracy, and judgement, which could eventually result in more strategic and controlled warfare.

**Reference**

[1] Siregar, R., & Aini, D. C. (2023). *The use of artificial intelligence in armed conflict under international law*. *Hasanuddin Law Review **[<http://pasca.unhas.ac.id/ojs/index.php/halrev/article/view/5267>](http://pasca.unhas.ac.id/ojs/index.php/halrev/article/view/5267)*

[2] O'Connell, M. E. (2023). *Banning autonomous weapons: A legal and ethical mandate*. *Ethics & International Affairs **[<https://www.cambridge.org/core/journals/ethics-and-international-affairs/article/banning-autonomous-weapons-a-legal-and-ethical-mandate/5FD01B5A96116766C3B1273490B24897#EN8>](https://www.cambridge.org/core/journals/ethics-and-international-affairs/article/banning-autonomous-weapons-a-legal-and-ethical-mandate/5FD01B5A96116766C3B1273490B24897#EN8)*
